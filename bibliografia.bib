@article{li2021recent,
  title={Recent developments of content-based image retrieval (CBIR)},
  author={Li, Xiaoqing and Yang, Jiansheng and Ma, Jinwen},
  journal={Neurocomputing},
  volume={452},
  pages={675--689},
  year={2021},
  issn={0925-2312},
  doi={10.1016/j.neucom.2020.07.139},
  url={https://www.sciencedirect.com/science/article/pii/S0925231220319044},
  abstract={With the development of Internet technology and the popularity of digital devices, Content-Based Image Retrieval (CBIR) has been quickly developed and applied in various fields related to computer vision and artificial intelligence. Currently, it is possible to retrieve related images effectively and efficiently from a large scale database with an input image. In the past ten years, great efforts have been made for new theories and models of CBIR and many effective CBIR algorithms have been established. In this paper, we present a survey on the fast developments and applications of CBIR theories and algorithms during the period from 2009 to 2019. We mainly review the technological developments from the viewpoint of image representation and database search. We further summarize the practical applications of CBIR in the fields of fashion image retrieval, person re-identification, e-commerce product retrieval, remote sensing image retrieval, and trademark image retrieval. Finally, we discuss the future research directions of CBIR with the challenge of big data and the utilization of deep learning techniques.},
  keywords={Content-based image retrieval; Image representation; Database search; Computer vision; Big data; Deep learning}
}

@article{ARMANIOUS2020101684,
title = {MedGAN: Medical image translation using GANs},
journal = {Computerized Medical Imaging and Graphics},
volume = {79},
pages = {101684},
year = {2020},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2019.101684},
url = {https://www.sciencedirect.com/science/article/pii/S0895611119300990},
author = {Karim Armanious and Chenming Jiang and Marc Fischer and Thomas Küstner and Tobias Hepp and Konstantin Nikolaou and Sergios Gatidis and Bin Yang},
keywords = {Generative adversarial networks, Deep neural networks, Image translation, PET attenuation correction, MR motion correction},
abstract = {Image-to-image translation is considered a new frontier in the field of medical image analysis, with numerous potential applications. However, a large portion of recent approaches offers individualized solutions based on specialized task-specific architectures or require refinement through non-end-to-end training. In this paper, we propose a new framework, named MedGAN, for medical image-to-image translation which operates on the image level in an end-to-end manner. MedGAN builds upon recent advances in the field of generative adversarial networks (GANs) by merging the adversarial framework with a new combination of non-adversarial losses. We utilize a discriminator network as a trainable feature extractor which penalizes the discrepancy between the translated medical images and the desired modalities. Moreover, style-transfer losses are utilized to match the textures and fine-structures of the desired target images to the translated images. Additionally, we present a new generator architecture, titled CasNet, which enhances the sharpness of the translated medical outputs through progressive refinement via encoder-decoder pairs. Without any application-specific modifications, we apply MedGAN on three different tasks: PET-CT translation, correction of MR motion artefacts and PET image denoising. Perceptual analysis by radiologists and quantitative evaluations illustrate that the MedGAN outperforms other existing translation approaches.}
}

@misc{redes-open,
    tittle ={Qué son las redes neuronales y sus aplicaciones},
    url = {https://openwebinars.net/blog/que-son-las-redes-neuronales-y-sus-aplicaciones/},
    year = {2023},
    author = {Pablo Huet},
}

@misc{aws-gan,
    tittle = {¿Qué es una GAN?},
    url = {https://aws.amazon.com/es/what-is/gan/#:~:text=Un%20sistema%20de%20redes%20generativas,salida%20es%20falsa%20o%20real.},
    year = {2023},
}

@article{calabuig2023modelos,
  title={Modelos de generaci{\'o}n de im{\'a}genes mediante texto en el dise{\~n}o conceptual de productos. Un caso de estudio empleando Midjourney.},
  author={Calabuig Llamas, Marta and Alcaide Marzal, Jorge and Diego M{\'a}s, Jos{\'e} Antonio},
  year={2023}
}

@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017},
  url={https://arxiv.org/abs/1706.03762}
}

@misc{baeldung-cbir,
  title={What is Content-Based Image Retrieval?},
  author={Simic, Milos},
  year={2024},
  howpublished={\url{https://www.baeldung.com/cs/cbir-tbir}}
}

@misc{gan-mathworks,
  title={Redes Generativas Antagónicas},
  howpublished={\url{https://es.mathworks.com/discovery/generative-adversarial-networks.html}},
  note={Consultado en abril de 2025}
}

@misc{datascientest-cgan,
  title={What is a Conditional Generative Adversarial Network (cGAN)?},
  howpublished={\url{https://datascientest.com/en/what-is-a-conditional-generative-adversarial-network-cgan}},
  year={2023}
}

@misc{educative-cgan,
  title={What is a Conditional GAN (cGAN)?},
  howpublished={\url{https://www.educative.io/answers/what-is-a-conditional-gan-cgan}},
  year={2024}
}

@book{tunstall2022transformers,
  title     = {Natural Language Processing with Transformers},
  author    = {Tunstall, Lewis and von Werra, Leandro and Wolf, Thomas},
  year      = {2022},
  publisher = {O'Reilly Media},
  isbn      = {9781098103244},
  url       = {https://transformersbook.com/}
}

@inproceedings{han2017stackgan,
  title={StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks},
  author={Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Wang, Xiaogang and Huang, Xiaolei and Metaxas, Dimitris},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={5907--5915},
  year={2017}
}

@inproceedings{xu2018attngan,
  title={AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks},
  author={Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1316--1324},
  year={2018}
}

@inproceedings{rombach2022highresolution,
  title     = {High-Resolution Image Synthesis with Latent Diffusion Models},
  author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {10684--10695},
  year      = {2022},
  archivePrefix = {arXiv},
  eprint    = {2112.10752},
  primaryClass = {cs.CV},
  doi       = {10.48550/arXiv.2112.10752},
  url       = {https://arxiv.org/abs/2112.10752}
}

@misc{mlc2023walkthrough,
  author = {{MLC AI}},
  title = {Stable Diffusion Walkthrough},
  year = {2023},
  howpublished = {\url{https://github.com/mlc-ai/web-stable-diffusion}},
  note = {Accedido el 4 de junio de 2025}
}


@article{ho2020denoising,
  title={Denoising Diffusion Probabilistic Models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2006.11239},
  year={2020}
}

@article{rombach2022high,
  title={High-Resolution Image Synthesis with Latent Diffusion Models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@book{szeliski2010computer,
  title     = {Computer Vision: Algorithms and Applications},
  author    = {Szeliski, Richard},
  year      = {2010},
  publisher = {Springer},
  isbn      = {9781848829343},
  doi       = {10.1007/978-1-84882-935-0},
  url       = {https://szeliski.org/Book/}
}

@misc{linkedin2023ia,
  title        = {Fundamentos profesionales de IA generativa por Microsoft y LinkedIn},
  author       = {{LinkedIn Learning} y Microsoft},
  year         = {2023},
  howpublished = {\url{https://www.linkedin.com/learning/paths/fundamentos-profesionales-de-ia-generativa-por-microsoft-y-linkedin}},
  note         = {Curso completado por la autora como parte de su formación en IA generativa}
}

